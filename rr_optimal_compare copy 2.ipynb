{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# import os\n",
    "import random\n",
    "\n",
    "\n",
    "from utils.empirical_data import *\n",
    "from mechanisms.mldp.mldp import *\n",
    "from mechanisms.k_rr_mechanism import *\n",
    "from mechanisms.mldp.repetitive_optimizer import *\n",
    "from utils.synthetic_dataset import *\n",
    "from mechanisms.exponential.exponential_mechanism import *\n",
    "from utils.simpleinfotheory import *\n",
    "from utils.normalize_error_matrix import *\n",
    "from utils.alphabet import *\n",
    "import matplotlib as mpl\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "mpl.rcParams.update({'font.size': 12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutual_info_pair(a, b):\n",
    "    return mutualinformationempirical(xn=a, yn=b)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I(A;A',B') = I(A;A') + I(A;B'|A')\n",
    "\n",
    "def conditional_mutual_info(a, b, c):\n",
    "    return conditionalmutualinformationempirical(a, b, c)\n",
    "\n",
    "def total_info_leakage(A, A_prime, B_prime):\n",
    "    return mutual_info_pair(A, A_prime) + conditional_mutual_info(A, B_prime, A_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutual_information(a, b):\n",
    "    processed_a = []\n",
    "    # print(a)\n",
    "    # print(b)\n",
    "    for i in a:\n",
    "        actual_split = i.split(\" \")\n",
    "        actual = []\n",
    "        # print(actual_split)\n",
    "        for j in actual_split:\n",
    "            # print(i)\n",
    "            if j != \"\" :\n",
    "                actual.append(int(j))\n",
    "        processed_a.append(np.array(actual))\n",
    "    processed_a = np.array(processed_a)\n",
    "    processed_b = []\n",
    "    \n",
    "    for i in b:\n",
    "        actual_split = i.split(\" \")\n",
    "        actual = []\n",
    "        # print(actual_split)\n",
    "        for j in actual_split:\n",
    "            # print(i)\n",
    "            if j != \"\" :\n",
    "                actual.append(int(j))\n",
    "        processed_b.append(np.array(actual))\n",
    "    processed_b = np.array(processed_b)\n",
    "\n",
    "    mi = []\n",
    "    # print(\"processed_a\", processed_a)\n",
    "    # print(\"processed_b\", processed_b)\n",
    "    # for i in range(np.shape(processed_b)[1]):\n",
    "    #     mi.append(mutual_info_pair(processed_a[:,i], processed_b[:,i]))\n",
    "    # mi.append(mutual_info_pair(processed_a[:,0], processed_a[:,1]))\n",
    "    # mi.append(mutual_info_pair(processed_b[:,1], processed_b[:,0]))\n",
    "    # mi.append(mutual_info_pair(processed_a[:,0], processed_b[:,0]))\n",
    "    # mi.append(mutual_info_pair(processed_a[:,1], processed_b[:,1]))\n",
    "    mi.append(total_info_leakage(processed_a[:,0], processed_b[:,0], processed_b[:,1]))\n",
    "    mi.append(total_info_leakage(processed_a[:,1], processed_b[:,1], processed_b[:,0]))\n",
    "    # mi.append(total_info_leakage(processed_a[:,0], processed_b[:,1], processed_b[:,0]))\n",
    "    return mi\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Test information leakage of attributes against their weight ratio.\n",
    "'''\n",
    "\n",
    "TARGET_UTILITY_ERROR = 0.15\n",
    "NUM_ATTRIBUTES = 2\n",
    "NUM_STATES = [6, 6]\n",
    "DATASET_SIZE = 15000\n",
    "EPS_ARRAY = np.arange(20, 70)*0.10\n",
    "plt.tight_layout()\n",
    "\n",
    "# priority_list = [{'1': 0.01*2/1.01, '0': 1*2/1.01}, {'1': 0.1*2/1.1, '0': 1*2/1.1}, {'1': 0.5*2/1.5, '0': 1*2/1.5}, {'1': 1, '0': 1}, {'1': 1*2/1.5, '0': 0.5*2/1.5}, {'1': 1*2/1.1, '0': 0.1*2/1.1}, {'1': 1*2/1.01, '0': 0.01*2/1.01}]\n",
    "priority_list = [{'1': 0.01, '0': 1}, {'1': 0.1, '0': 1}, {'1': 0.5, '0': 1}, {'1': 1, '0': 1}, {'1': 1, '0': 0.5}, {'1': 1, '0': 0.1}, {'1': 1, '0': 0.01}]\n",
    "# priority_list = [{'1': 100, '0': 1}, {'1': 50, '0': 1}, {'1': 20, '0': 1}, {'1': 1, '0': 1}] \n",
    "distribution_list = np.ones(36)/36 # [0.3, 0.01, 0.01, 0.01, 0.30, 0.01, 0.01, 0.01, 0.34]\n",
    "\n",
    "colour_err_ = {\"k-RR\": \"red\", \"Optimal k-RR\": \"blue\"}\n",
    "colour_mi_ = {\"k-RR\": [\"lightsalmon\", \"brown\"], \"Optimal k-RR\": [\"green\", \"purple\"]}\n",
    "\n",
    "values_k_rr = []\n",
    "values_optimal = []\n",
    "\n",
    "for priority_dict in priority_list:\n",
    "    random_dist = distribution_list\n",
    "    TOTAL_STATES = 1\n",
    "    alphabet_dict = {}\n",
    "    for i in range(NUM_ATTRIBUTES):\n",
    "        TOTAL_STATES *= NUM_STATES[i]\n",
    "        alphabet_dict[str(i)] = np.arange(NUM_STATES[i])\n",
    "\n",
    "    ALL_ALPHABET = create_alphabet(attributes_with_alphabet=alphabet_dict)\n",
    "    STRING_ALL_ALPHABET = convert_alphabet_to_string(ALL_ALPHABET)\n",
    "    ATTRIBUTE_LIST = list(alphabet_dict.keys())\n",
    "\n",
    "    synthetic_dataset_constructor = Gen_Synthetic_Dataset(no_of_states = TOTAL_STATES, no_of_samples = DATASET_SIZE, alphabet=STRING_ALL_ALPHABET)\n",
    "    correlated_synthetic_dataset = synthetic_dataset_constructor.gen_custom(distribution=random_dist)\n",
    "\n",
    "    alphabet_dict = {}\n",
    "    for i in range(len(ALL_ALPHABET)):\n",
    "        alphabet_dict[str(ALL_ALPHABET[i])] = i\n",
    "    normalize_error_matrix = Normalize_error_matrix(attribute_list=ATTRIBUTE_LIST, alphabet=ALL_ALPHABET, priority_dict=priority_dict, alphabet_dict=alphabet_dict)\n",
    "    err_matrix = normalize_error_matrix.normalized_error_matrix\n",
    "    # sns.heatmap(err_matrix)\n",
    "    # plt.show()\n",
    "    random_response_mechanism = Randomized_Response(STATE_COUNT=TOTAL_STATES, INPUT_ALPHABET=STRING_ALL_ALPHABET, normalized_objective_err_matrix=err_matrix)\n",
    "\n",
    "    optimal_random_response_mechanism = Optimized_Randomized_Response(prior_dist = random_dist, STATE_COUNT = TOTAL_STATES, INPUT_ALPHABET = STRING_ALL_ALPHABET, normalized_objective_err_matrix = err_matrix, \n",
    "                        TOLERANCE_MARGIN = 0.01, APPROXIMATION = \"LINEAR\", solver = \"SCS\", is_kl_div = True, ALPHA=0.01, accelerate_from_rr=True)\n",
    "\n",
    "    mechanisms_dict = {\"k-RR\": random_response_mechanism, \"Optimal k-RR\": optimal_random_response_mechanism}\n",
    "\n",
    "    error_dict = {}\n",
    "    mi_dict = {}\n",
    "\n",
    "    for key in list(mechanisms_dict.keys()):\n",
    "        error_dict[key] = []\n",
    "        mi_dict[key] = []\n",
    "\n",
    "    for mechanism in list(mechanisms_dict.keys()):\n",
    "        for eps in EPS_ARRAY:\n",
    "        \n",
    "            __tot_error = 0\n",
    "            __perturbed_value_list = []\n",
    "            for entry in correlated_synthetic_dataset:\n",
    "                __perturbed_value_list.append(mechanisms_dict[mechanism].gen_random_output(actual_value=entry, eps=eps)[0])\n",
    "\n",
    "                __error = normalize_error_matrix.get_value_error(actual=entry, perturbed=__perturbed_value_list[-1])\n",
    "                __tot_error += __error\n",
    "            \n",
    "            error_dict[mechanism].append(__tot_error/len(correlated_synthetic_dataset))\n",
    "\n",
    "            if error_dict[mechanism][-1] < TARGET_UTILITY_ERROR:\n",
    "                mi_dict[mechanism].append(mutual_information(correlated_synthetic_dataset, __perturbed_value_list))\n",
    "                break\n",
    "\n",
    "    values_k_rr.append(mi_dict[\"k-RR\"][0])\n",
    "    values_optimal.append(mi_dict[\"Optimal k-RR\"][0])\n",
    "\n",
    "values_k_rr = np.array(values_k_rr)\n",
    "values_optimal = np.array(values_optimal)\n",
    "\n",
    "x = np.arange(len(priority_list))  # the label locations\n",
    "width = 0.1  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, values_k_rr[:, 0], width, label='Feature 1')\n",
    "rects2 = ax.bar(x + width/2, values_k_rr[:, 1], width, label='Feature 2')\n",
    "rects2 = ax.bar(x + width + width/2, values_optimal[:, 0], width, label='Feature 2')\n",
    "rects2 = ax.bar(x + width*2 + width/2, values_optimal[:, 1], width, label='Feature 2')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 99\u001b[0m\n\u001b[1;32m     95\u001b[0m         randomized_value_list \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m last_value \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m randomized_value_list\n\u001b[0;32m---> 99\u001b[0m \u001b[43mcreate_optimal_mechnism_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43malphabet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mALL_ALPHABET\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malphabet_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malphabet_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprior_dist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_dist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merr_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m0_1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 36\u001b[0m, in \u001b[0;36mcreate_optimal_mechnism_dict\u001b[0;34m(alphabet, alphabet_dict, prior_dist, err_type, uniform)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NUM_ATTRIBUTES):\n\u001b[1;32m     35\u001b[0m     mechanism_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 36\u001b[0m     individual_alphabet \u001b[38;5;241m=\u001b[39m \u001b[43malphabet_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;66;03m# print(\"individual_alphabet \", convert_alphabet_to_string(individual_alphabet))\u001b[39;00m\n\u001b[1;32m     38\u001b[0m     state_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(individual_alphabet)\n",
      "\u001b[0;31mKeyError\u001b[0m: '0'"
     ]
    }
   ],
   "source": [
    "def get_mechanism_key(predessor_index_list):\n",
    "    __key = \"\"\n",
    "    for i in predessor_index_list:\n",
    "        __key += str(i) + \" \"\n",
    "    return __key\n",
    "\n",
    "def string_to_list(s):\n",
    "    l = []\n",
    "    actual_split = s.split(\" \")\n",
    "    for j in actual_split:\n",
    "        if j != \"\" :\n",
    "            l.append((j))\n",
    "    return l\n",
    "\n",
    "def get_conditional_dist(attribute_num, predessor_index_list, individual_alphabet, global_alphabet, prior_dist):\n",
    "    __marginal_prob_dist = []\n",
    "    k = len(predessor_index_list)\n",
    "    # print(\"predessor_index_list \", predessor_index_list)\n",
    "    for i in individual_alphabet:\n",
    "        __marginal_prob = 0\n",
    "        for index_j, j in enumerate(global_alphabet):\n",
    "            # print(\"j[:k] \", j[:k], list(j[:k]) == list(predessor_index_list), j[attribute_num] == i, k == 0)\n",
    "            if j[attribute_num] == i and (k == 0 or list(j[:k]) == list(predessor_index_list)):\n",
    "                __marginal_prob += prior_dist[index_j]\n",
    "        __marginal_prob_dist.append(__marginal_prob)\n",
    "    return __marginal_prob_dist/sum(__marginal_prob_dist)\n",
    "\n",
    "\n",
    "def create_optimal_mechnism_dict(alphabet = [], alphabet_dict = {}, prior_dist = [], err_type = \"0_1\", uniform = False):\n",
    "    mechanism_list = []\n",
    "    # print(\"alphabet \", len(alphabet), alphabet)\n",
    "    # print(\"alphabet_dict \", len(alphabet_dict), alphabet_dict)\n",
    "    # print(\"prior_dist \", len(prior_dist), prior_dist)\n",
    "    for i in range(NUM_ATTRIBUTES):\n",
    "        mechanism_dict = {}\n",
    "        individual_alphabet = alphabet_dict[str(i)]\n",
    "        # print(\"individual_alphabet \", convert_alphabet_to_string(individual_alphabet))\n",
    "        state_count = len(individual_alphabet)\n",
    "        normalize_error_matrix = Normalize_error_matrix(attribute_list=[str(i)], alphabet=individual_alphabet, priority_dict=priority_dict, alphabet_dict=alphabet_dict, err_type=err_type)\n",
    "        err_matrix = normalize_error_matrix.normalized_error_matrix\n",
    "        # sns.heatmap(err_matrix)\n",
    "        # plt.show()\n",
    "        for index_j, j in enumerate(alphabet):\n",
    "            predessor_index_list = j[:i]\n",
    "            if len(predessor_index_list) == 0:\n",
    "                if uniform:\n",
    "                    conditional_prior_dist = np.ones(len(individual_alphabet))/len(individual_alphabet)\n",
    "                else:\n",
    "                    conditional_prior_dist = get_conditional_dist(i, predessor_index_list, (individual_alphabet), alphabet, prior_dist)\n",
    "                # err_matrix_1 = err_matrix*(1- conditional_prior_dist) #(1/(conditional_prior_dist+0.00000001))\n",
    "                # err_matrix_1 = err_matrix_1 / np.max(err_matrix_1)\n",
    "                # sns.heatmap(err_matrix_1)\n",
    "                # plt.show()\n",
    "                # print(\"conditional_prior_dist \", len(conditional_prior_dist), conditional_prior_dist)\n",
    "                # conditional_prior_dist = np.ones(len(conditional_prior_dist))/len(conditional_prior_dist)\n",
    "                optimal_random_response_mechanism = Optimized_Randomized_Response(prior_dist = conditional_prior_dist, STATE_COUNT = state_count, INPUT_ALPHABET = convert_alphabet_to_string(individual_alphabet), normalized_objective_err_matrix = err_matrix, \n",
    "                    TOLERANCE_MARGIN = 0.01, APPROXIMATION = \"LINEAR\", solver = \"SCS\", is_kl_div = True, ALPHA=0.01, accelerate_from_rr=False)\n",
    "                mechanism_dict[\"0\"] = optimal_random_response_mechanism\n",
    "                # sns.heatmap(optimal_random_response_mechanism.get_mechanism(2), annot=True)\n",
    "                # plt.show()\n",
    "                break\n",
    "            __key = get_mechanism_key(predessor_index_list = predessor_index_list)\n",
    "            # print(__key)\n",
    "            if __key not in mechanism_dict.keys():\n",
    "                if uniform:\n",
    "                    conditional_prior_dist = np.ones(len(individual_alphabet))/len(individual_alphabet)\n",
    "                else:\n",
    "                    conditional_prior_dist = get_conditional_dist(i, predessor_index_list, (individual_alphabet), alphabet, prior_dist)\n",
    "                # err_matrix_2 = err_matrix*(1- conditional_prior_dist) # *(1/(conditional_prior_dist+0.00000001))\n",
    "                # err_matrix_2 = err_matrix_2 / np.max(err_matrix_2)\n",
    "                # sns.heatmap(err_matrix_2)\n",
    "                # plt.show()\n",
    "                # print(\"conditional_prior_dist \", len(conditional_prior_dist), conditional_prior_dist)\n",
    "                # conditional_prior_dist = np.ones(len(conditional_prior_dist))/len(conditional_prior_dist)\n",
    "                optimal_random_response_mechanism = Optimized_Randomized_Response(prior_dist = conditional_prior_dist, STATE_COUNT = state_count, INPUT_ALPHABET = convert_alphabet_to_string(individual_alphabet), normalized_objective_err_matrix = err_matrix, \n",
    "                    TOLERANCE_MARGIN = 0.01, APPROXIMATION = \"LINEAR\", solver = \"SCS\", is_kl_div = True, ALPHA=0.01, accelerate_from_rr=False)\n",
    "                mechanism_dict[__key] = optimal_random_response_mechanism\n",
    "                # sns.heatmap(optimal_random_response_mechanism.get_mechanism(2), annot=True)\n",
    "                # plt.show()\n",
    "        mechanism_list.append(mechanism_dict)\n",
    "        # print(\"mechanism_list \", mechanism_list)\n",
    "    return mechanism_list\n",
    "\n",
    "def get_randomized_value(actual_value, eps, mechanism_list):\n",
    "    actual_value = string_to_list(actual_value)\n",
    "    last_value = None\n",
    "    randomized_value_list = \"\"\n",
    "    # print(\"actual_value \", actual_value)\n",
    "    for index_i, i in enumerate(actual_value):\n",
    "        if last_value == None:\n",
    "            last_value = mechanism_list[index_i][\"0\"].gen_random_output(actual_value=i, eps=eps)[0]\n",
    "        else:\n",
    "            __key = randomized_value_list  #get_mechanism_key(predessor_index_list=randomized_value_list)\n",
    "            last_value = mechanism_list[index_i][__key].gen_random_output(actual_value=i, eps=eps)[0]\n",
    "        randomized_value_list += last_value + \" \"\n",
    "    return randomized_value_list\n",
    "\n",
    "            \n",
    "create_optimal_mechnism_dict(alphabet=ALL_ALPHABET, alphabet_dict=alphabet_dict, prior_dist=random_dist, err_type=\"0_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "mechanism  [0.6731, 0.6712, 0.6622, 0.6625, 0.6616, 0.6668, 0.6719, 0.675, 0.6605, 0.6635]\n",
      "mechanism  [0.3704, 0.3761, 0.3739, 0.3366, 0.3765, 0.3737, 0.3941, 0.3329, 0.3788, 0.3801]\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "mechanism  [0.6599, 0.6661, 0.6653, 0.6617, 0.6607, 0.6719, 0.6764, 0.6731, 0.6738, 0.6766]\n",
      "mechanism  [0.3524, 0.3633, 0.366, 0.3665, 0.3762, 0.3902, 0.3757, 0.3428, 0.3774, 0.3508]\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "mechanism  [0.6735, 0.6717, 0.6677, 0.662, 0.6702, 0.6704, 0.6702, 0.6691, 0.6673, 0.6788]\n",
      "mechanism  [0.3558, 0.3742, 0.3476, 0.3771, 0.3558, 0.3486, 0.3693, 0.347, 0.3602, 0.3687]\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "mechanism  [0.6759, 0.6712, 0.66, 0.6654, 0.6679, 0.6713, 0.6637, 0.674, 0.6644, 0.6723]\n",
      "mechanism  [0.3231, 0.3184, 0.3356, 0.3232, 0.3349, 0.3419, 0.3491, 0.3632, 0.3134, 0.3429]\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "mechanism  [0.6687, 0.6636, 0.6587, 0.6611, 0.6681, 0.6719, 0.669, 0.6601, 0.6702, 0.6764]\n",
      "mechanism  [0.3296, 0.3147, 0.34, 0.3438, 0.3305, 0.3509, 0.3297, 0.2983, 0.3276, 0.3249]\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "mechanism  [0.6717, 0.6687, 0.6732, 0.6666, 0.6632, 0.679, 0.6622, 0.6628, 0.6776, 0.6663]\n",
      "mechanism  [0.2949, 0.3133, 0.3346, 0.3023, 0.3364, 0.2995, 0.316, 0.3135, 0.2705, 0.3124]\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "mechanism  [0.667, 0.6656, 0.6666, 0.6616, 0.6686, 0.6703, 0.6782, 0.6714, 0.679, 0.6715]\n",
      "mechanism  [0.3018, 0.29, 0.314, 0.2919, 0.3042, 0.2893, 0.2794, 0.2769, 0.3107, 0.2688]\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "mechanism  [0.6681, 0.6707, 0.6726, 0.6765, 0.6547, 0.6718, 0.6689, 0.6763, 0.669, 0.6588]\n",
      "mechanism  [0.2537, 0.2906, 0.3011, 0.3017, 0.2828, 0.2651, 0.2912, 0.2992, 0.2887, 0.3032]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "    Test information leakage of attributes against different corrlations\n",
    "'''\n",
    "\n",
    "TARGET_UTILITY_ERROR = 0.2\n",
    "NUM_ATTRIBUTES = 2\n",
    "NUM_STATES = [3, 3]\n",
    "DATASET_SIZE = 10000\n",
    "EPS_ARRAY = np.arange(40)*0.16\n",
    "plt.tight_layout()\n",
    "\n",
    "priority_list = [{'1': 0.01, '0': 1}, {'1': 0.1, '0': 1}, {'1': 0.5, '0': 1}, {'1': 1, '0': 1}, {'1': 1, '0': 0.5}, {'1': 1, '0': 0.1}, {'1': 1, '0': 0.01}]\n",
    "# priority_list = [{'1': 100, '0': 1}, {'1': 50, '0': 1}, {'1': 20, '0': 1}, {'1': 1, '0': 1}] \n",
    "# distribution_list = [0.3, 0.01, 0.01, 0.01, 0.30, 0.01, 0.01, 0.01, 0.34]\n",
    "\n",
    "synthetic_dist = Gen_Synthetic_Distribution(original_dist=np.ones(9)/9, no_samples=20, sample_count_per_sample=100, div_type = \"MI\", attribute_state_count=NUM_STATES)\n",
    "synthetic_dist.create_distribution()\n",
    "synthetic_distribution_dict = synthetic_dist.get_synthetic_distribution()\n",
    "distribution_list = list(synthetic_distribution_dict.values())\n",
    "\n",
    "colour_err_ = {\"k-RR\": \"red\", \"Optimal k-RR\": \"blue\"}\n",
    "colour_mi_ = {\"k-RR\": [\"lightsalmon\", \"brown\"], \"Optimal k-RR\": [\"green\", \"purple\"]}\n",
    "\n",
    "values_k_rr = []\n",
    "values_optimal = []\n",
    "\n",
    "for random_dist_list in distribution_list:\n",
    "    if len(random_dist_list) == 0:\n",
    "        continue\n",
    "    error_dict = {}\n",
    "    mi_dict = {}\n",
    "\n",
    "    for key in list(mechanisms_dict.keys()):\n",
    "        error_dict[key] = []\n",
    "        mi_dict[key] = []\n",
    "    for random_dist in random_dist_list[:min(10,len(random_dist_list))]:\n",
    "        priority_dict =  {'1': 1, '0': 1}\n",
    "        TOTAL_STATES = 1\n",
    "        alphabet_dict = {}\n",
    "        for i in range(NUM_ATTRIBUTES):\n",
    "            TOTAL_STATES *= NUM_STATES[i]\n",
    "            alphabet_dict[str(i)] = np.arange(NUM_STATES[i])\n",
    "\n",
    "        ALL_ALPHABET = create_alphabet(attributes_with_alphabet=alphabet_dict)\n",
    "        STRING_ALL_ALPHABET = convert_alphabet_to_string(ALL_ALPHABET)\n",
    "        ATTRIBUTE_LIST = list(alphabet_dict.keys())\n",
    "        alphabet_dict_ = alphabet_dict\n",
    "\n",
    "        synthetic_dataset_constructor = Gen_Synthetic_Dataset(no_of_states = TOTAL_STATES, no_of_samples = DATASET_SIZE, alphabet=STRING_ALL_ALPHABET)\n",
    "        correlated_synthetic_dataset = synthetic_dataset_constructor.gen_custom(distribution=random_dist)\n",
    "\n",
    "        alphabet_dict = {}\n",
    "        for i in range(len(ALL_ALPHABET)):\n",
    "            alphabet_dict[str(ALL_ALPHABET[i])] = i\n",
    "        normalize_error_matrix = Normalize_error_matrix(attribute_list=ATTRIBUTE_LIST, alphabet=ALL_ALPHABET, priority_dict=priority_dict, alphabet_dict=alphabet_dict)\n",
    "        err_matrix = normalize_error_matrix.normalized_error_matrix\n",
    "        # sns.heatmap(err_matrix)\n",
    "        # plt.show()\n",
    "        random_response_mechanism = Randomized_Response(STATE_COUNT=TOTAL_STATES, INPUT_ALPHABET=STRING_ALL_ALPHABET, normalized_objective_err_matrix=err_matrix)\n",
    "        # random_response_mechanism = Exponential_mechanism(prior_dist=random_dist, STATE_COUNT=TOTAL_STATES, INPUT_ALPHABET=STRING_ALL_ALPHABET, normalized_objective_err_matrix=err_matrix, only_err_matrix=True)\n",
    "        # optimal_random_response_mechanism = Optimized_Randomized_Response(prior_dist = random_dist, STATE_COUNT = TOTAL_STATES, INPUT_ALPHABET = STRING_ALL_ALPHABET, normalized_objective_err_matrix = err_matrix, \n",
    "        #                     TOLERANCE_MARGIN = 0.01, APPROXIMATION = \"LINEAR\", solver = \"SCS\", is_kl_div = True, ALPHA=0.01, accelerate_from_rr=True)\n",
    "        optimal_mechanism_list = create_optimal_mechnism_dict(alphabet=ALL_ALPHABET, alphabet_dict=alphabet_dict_, prior_dist=random_dist, err_type=\"0_1\")\n",
    "        optimal_mechanism_list_divided = create_optimal_mechnism_dict(alphabet=ALL_ALPHABET, alphabet_dict=alphabet_dict_, prior_dist=random_dist, err_type=\"0_1\", uniform=True)\n",
    "        mechanisms_dict = {\"k-RR\": random_response_mechanism, \"Optimal k-RR\": optimal_random_response_mechanism}\n",
    "\n",
    "        \n",
    "\n",
    "        for mechanism in list(mechanisms_dict.keys()):\n",
    "            for eps in [2]: # EPS_ARRAY:\n",
    "            \n",
    "                __tot_error = 0\n",
    "                __perturbed_value_list = []\n",
    "                for entry in correlated_synthetic_dataset:\n",
    "                    if mechanism == \"Optimal k-RR\":\n",
    "                        __perturbed_value_list.append(get_randomized_value(actual_value=entry, eps=eps, mechanism_list=optimal_mechanism_list))\n",
    "                    elif mechanism == \"k-RR\":\n",
    "                        __perturbed_value_list.append(get_randomized_value(actual_value=entry, eps=eps/2, mechanism_list=optimal_mechanism_list_divided))\n",
    "                    else:\n",
    "                        __perturbed_value_list.append(mechanisms_dict[mechanism].gen_random_output(actual_value=entry, eps=eps)[0])\n",
    "\n",
    "                    __error = normalize_error_matrix.get_value_error(actual=entry, perturbed=__perturbed_value_list[-1])\n",
    "                    __tot_error += __error\n",
    "                \n",
    "                error_dict[mechanism].append(__tot_error/len(correlated_synthetic_dataset))\n",
    "    for mechanism in list(mechanisms_dict.keys()):\n",
    "        print(\"mechanism \",error_dict[mechanism])\n",
    "        error_dict[mechanism] = sum(error_dict[mechanism])/len(error_dict[mechanism])\n",
    "    values_k_rr.append(error_dict[\"k-RR\"])\n",
    "    values_optimal.append(error_dict[\"Optimal k-RR\"])\n",
    "\n",
    "# values_k_rr = np.array(values_k_rr)\n",
    "# values_optimal = np.array(values_optimal)\n",
    "\n",
    "x = np.arange(len(values_k_rr))  # the label locations\n",
    "width = 0.1  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, values_k_rr, width, label='Feature 1')\n",
    "rects2 = ax.bar(x + width/2, values_optimal, width, label='Feature 2')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(len(values_k_rr))  # the label locations\n",
    "width = 0.1  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, values_k_rr, width, label='Feature 1')\n",
    "rects2 = ax.bar(x + width/2, values_optimal, width, label='Feature 2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
